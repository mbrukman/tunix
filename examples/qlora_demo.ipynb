{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-gq1gcpyCpT"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google/tunix/blob/main/examples/qlora_demo.ipynb\" ><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "## Install necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RTlz7JP7yCpT"
      },
      "outputs": [],
      "source": [
        "!pip install -q kagglehub\n",
        "\n",
        "!pip install -q tensorflow\n",
        "!pip install -q tensorboardX\n",
        "!pip install -q grain\n",
        "!pip install -q datasets\n",
        "# !pip install -q git+https://github.com/google/tunix\n",
        "!pip install -q git+https://github.com/google/qwix\n",
        "\n",
        "!pip uninstall -q -y flax\n",
        "!pip install -q git+https://github.com/google/flax.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-datasets in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (4.9.9)\n",
            "Requirement already satisfied: absl-py in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (2.3.1)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (0.7.2)\n",
            "Requirement already satisfied: dm-tree in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (0.1.9)\n",
            "Requirement already satisfied: etils>=1.9.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.12.2)\n",
            "Requirement already satisfied: immutabledict in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (4.2.1)\n",
            "Requirement already satisfied: numpy in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (2.1.3)\n",
            "Requirement already satisfied: promise in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (5.29.5)\n",
            "Requirement already satisfied: psutil in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (7.0.0)\n",
            "Requirement already satisfied: pyarrow in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (20.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (2.32.4)\n",
            "Requirement already satisfied: simple_parsing in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (1.17.2)\n",
            "Requirement already satisfied: termcolor in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (3.1.0)\n",
            "Requirement already satisfied: toml in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-datasets) (1.17.2)\n",
            "Requirement already satisfied: einops in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (4.14.1)\n",
            "Requirement already satisfied: zipp in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets) (2025.7.9)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from dm-tree->tensorflow-datasets) (25.3.0)\n",
            "Requirement already satisfied: six in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from promise->tensorflow-datasets) (1.17.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from simple_parsing->tensorflow-datasets) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.70.0)\n",
            "Requirement already satisfied: aqtp in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (0.8.4)\n",
            "Requirement already satisfied: absl-py in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from aqtp) (2.3.1)\n",
            "Requirement already satisfied: jax in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from aqtp) (0.6.2)\n",
            "Requirement already satisfied: jaxlib in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from aqtp) (0.6.2)\n",
            "Requirement already satisfied: flax in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from aqtp) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from flax->aqtp) (2.1.3)\n",
            "Requirement already satisfied: msgpack in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from flax->aqtp) (1.1.1)\n",
            "Requirement already satisfied: optax in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from flax->aqtp) (0.2.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from flax->aqtp) (0.11.19)\n",
            "Requirement already satisfied: tensorstore in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from flax->aqtp) (0.1.76)\n",
            "Requirement already satisfied: rich>=11.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from flax->aqtp) (14.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from flax->aqtp) (4.14.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from flax->aqtp) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from flax->aqtp) (0.1.9)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from jax->aqtp) (0.5.1)\n",
            "Requirement already satisfied: opt_einsum in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from jax->aqtp) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from jax->aqtp) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from rich>=11.1->flax->aqtp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from rich>=11.1->flax->aqtp) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->aqtp) (0.1.2)\n",
            "Requirement already satisfied: chex>=0.1.87 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from optax->flax->aqtp) (0.1.89)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from chex>=0.1.87->optax->flax->aqtp) (1.0.0)\n",
            "Requirement already satisfied: etils[epath,epy] in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from orbax-checkpoint->flax->aqtp) (1.12.2)\n",
            "Requirement already satisfied: nest_asyncio in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from orbax-checkpoint->flax->aqtp) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from orbax-checkpoint->flax->aqtp) (5.29.5)\n",
            "Requirement already satisfied: humanize in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from orbax-checkpoint->flax->aqtp) (4.12.3)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from orbax-checkpoint->flax->aqtp) (3.20.1)\n",
            "Requirement already satisfied: fsspec in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from etils[epath,epy]->orbax-checkpoint->flax->aqtp) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from etils[epath,epy]->orbax-checkpoint->flax->aqtp) (6.5.2)\n",
            "Requirement already satisfied: zipp in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from etils[epath,epy]->orbax-checkpoint->flax->aqtp) (3.23.0)\n",
            "Requirement already satisfied: pillow in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (11.3.0)\n",
            "Requirement already satisfied: omegaconf in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from omegaconf) (6.0.2)\n",
            "Requirement already satisfied: google-cloud-storage in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (3.2.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.26.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-cloud-storage) (2.40.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.15.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-cloud-storage) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-cloud-storage) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-cloud-storage) (2.32.4)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-cloud-storage) (1.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2025.7.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-datasets\n",
        "!pip install aqtp\n",
        "!pip install pillow>=11.1.0\n",
        "!pip install pillow\n",
        "!pip install omegaconf\n",
        "!pip install google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_text in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (2.19.0)\n",
            "Requirement already satisfied: transformers in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (4.53.1)\n",
            "Requirement already satisfied: tiktoken in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (0.9.0)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow_text) (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (3.4.0)\n",
            "Requirement already satisfied: packaging in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (1.73.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (3.1.3)\n",
            "Requirement already satisfied: filelock in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (0.45.1)\n",
            "Requirement already satisfied: rich in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (14.0.0)\n",
            "Requirement already satisfied: namex in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (0.1.0)\n",
            "Requirement already satisfied: optree in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/mazumdera_google_com/venv-py311/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow_text) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_text transformers tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEjoS0-JyCpT"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LshEMmSzx6W6"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import time\n",
        "\n",
        "from flax import nnx\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import kagglehub\n",
        "import optax\n",
        "from orbax import checkpoint as ocp\n",
        "from qwix import lora\n",
        "from tunix.generate import sampler as sampler_lib\n",
        "from tunix.models.gemma import data as data_lib\n",
        "from tunix.models.gemma import gemma as gemma_lib\n",
        "from tunix.models.gemma import params as params_lib\n",
        "from tunix.sft import metrics_logger\n",
        "from tunix.sft import peft_trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnEZ_jXwypn-"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QBcMaL22T3Uu"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Model\n",
        "MESH = [(1, 8), (\"fsdp\", \"tp\")]\n",
        "# LoRA\n",
        "RANK = 16\n",
        "ALPHA = 2.0\n",
        "\n",
        "# Train\n",
        "MAX_STEPS = 100\n",
        "EVAL_EVERY_N_STEPS = 20\n",
        "NUM_EPOCHS = 3\n",
        "\n",
        "\n",
        "# Checkpoint saving\n",
        "INTERMEDIATE_CKPT_DIR = \"~/qlora_expt/content/intermediate_ckpt/\"\n",
        "CKPT_DIR = \"~/qlora_expt/content/ckpts/\"\n",
        "PROFILING_DIR = \"~/qlora_expt/content/profiling/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3s5Qg6xT3Uu"
      },
      "source": [
        "## Load Gemma 2B\n",
        "\n",
        "To load the model, you need to be on [Kaggle](https://www.kaggle.com/) and need\n",
        "to have agreed to the Gemma license\n",
        "[here](https://www.kaggle.com/models/google/gemma/flax/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o_7Sk8d7T3Uu"
      },
      "outputs": [],
      "source": [
        "# Log in\n",
        "# if \"KAGGLE_USERNAME\" not in os.environ or \"KAGGLE_KEY\" not in os.environ:\n",
        "  # kagglehub.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oJC3Hfh9T3Uv"
      },
      "outputs": [],
      "source": [
        "kaggle_ckpt_path = kagglehub.model_download(\"google/gemma/flax/2b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "r_5FWrq-T3Uv"
      },
      "outputs": [],
      "source": [
        "# # This is a workaround. The checkpoints on Kaggle don't work with NNX. So, we\n",
        "# # load the model, save the checkpoint locally, and then reload the model\n",
        "# # (sharded).\n",
        "# params = params_lib.load_and_format_params(os.path.join(kaggle_ckpt_path, \"2b\"))\n",
        "# gemma = gemma_lib.Transformer.from_params(params, version=\"2b\")\n",
        "# checkpointer = ocp.StandardCheckpointer()\n",
        "# _, state = nnx.split(gemma)\n",
        "# checkpointer.save(os.path.join(INTERMEDIATE_CKPT_DIR, \"state\"), state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_ertAr6FT3Uv"
      },
      "outputs": [],
      "source": [
        "# # # Wait for the ckpt to save successfully.\n",
        "# time.sleep(60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nGYKuLyFT3Uv"
      },
      "outputs": [],
      "source": [
        "# # Delete the intermediate model to save memory.\n",
        "# del params\n",
        "# del gemma\n",
        "# del state\n",
        "# gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-29 22:42:57.607765: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753828977.620627 1583231 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753828977.624519 1583231 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1753828977.636120 1583231 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753828977.636132 1583231 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753828977.636134 1583231 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753828977.636135 1583231 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# add the parent directory (one level up) to sys.path\n",
        "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../maxtext')))\n",
        "\n",
        "# ! pip install -r ../../maxtext/requirements.txt\n",
        "\n",
        "import MaxText as mt\n",
        "from MaxText import pyconfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flax @ git+https://github.com/google/flax.git@c9fc00b44a3e0ec161194dc2b9a63bc99ec937f1\n"
          ]
        }
      ],
      "source": [
        "! pip freeze | grep flax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from MaxText.layers import nnx_wrappers\n",
        "\n",
        "def get_ref_maxtext_model():\n",
        "\n",
        "  #python3 -m MaxText.train MaxText/configs/base.yml base_output_directory=${BASE_OUTPUT_DIRECTORY} dataset_path=${DATASET_PATH} tokenizer_path=assets/tokenizer.gemma load_parameters_path=${CONVERTED_CHECKPOINT} per_device_batch_size=1 run_name=${FINETUNE_RUN_NAME} max_target_length=8192 steps=10 async_checkpointing=false model_name=gemma-2b checkpoint_period=5\n",
        "\n",
        "  #TODO: @mazumdera: change this to use Gemma2-2b-it\n",
        "  config = pyconfig.initialize(\n",
        "      [\"\", \"../../maxtext/MaxText/configs/base.yml\"], #TODO: @mazumdera: why decode.py?\n",
        "      base_output_directory=\"gs://dummy_output_dir\",  # This is not used in Tunix.\n",
        "      run_name=\"test-tunix-maxtext-llama3-8b\",\n",
        "      # dataset_path=we use Tunix's dataset\n",
        "      # load_parameters_path=\"gs://maxtext-gemma/2b/\", #TODO: @mazumdera: change this to use checkpoint\n",
        "      tokenizer_type=\"tiktoken\",\n",
        "      tokenizer_path=\"../../maxtext/assets/tokenizer_llama3.tiktoken\",\n",
        "      per_device_batch_size=1,\n",
        "      max_target_length=8192,\n",
        "      steps=10,\n",
        "      async_checkpointing=\"false\",\n",
        "      model_name=\"llama3-8b\",\n",
        "      checkpoint_period=5,\n",
        "      skip_jax_distributed_system=\"true\",\n",
        "\n",
        "  )\n",
        "  #TODO: Anisha: \n",
        "  model = mt.from_pretrained(config)\n",
        "\n",
        "  #TODO @mazumdera: change this to pdbs*num_of_devices\n",
        "  # pdbs = config.per_device_batch_size\n",
        "  # batch_size \n",
        "  dummy_tokens = jnp.zeros((1, config.max_target_length), dtype=jnp.int32)\n",
        "  dummy_pos    = jnp.zeros_like(dummy_tokens)\n",
        "  # Anisha: using ToNNX bridge\n",
        "  model = nnx_wrappers.ToNNX(model, rngs=nnx.Rngs(params=0,dropout=0)).lazy_init(decoder_input_tokens = dummy_tokens,\n",
        "                                                                decoder_positions=dummy_pos,\n",
        "                                                                decoder_segment_ids = dummy_pos)\n",
        "  #TODO: @mazumdera: change this to extract decoder_segment_ids from attention mask\n",
        "\n",
        "\n",
        "  # rngs = nnx.Rngs(1234)\n",
        "  # model = build_tunix_wrapper(\n",
        "  #       config,\n",
        "  #       rngs,\n",
        "  #       enable_dropout=False,   # deterministic SFT (you can override at runtime)\n",
        "  #       init_batch_size=1,\n",
        "  #       init_seq_len=1,\n",
        "  #       use_attention_mask=False,  # trust Tunix loss masking\n",
        "  #   )\n",
        "  mesh  = model.mesh\n",
        "  \n",
        "\n",
        "  # We can continue to use Tunix's model_config\n",
        "  model_config = gemma_lib.TransformerConfig.gemma2_2b()\n",
        "\n",
        "  # Add these lines to properly get the graph definition and state\n",
        "  graphdef, state = nnx.split(model)\n",
        "  model = nnx.merge(graphdef, state)  # Recreate model in proper NNX format\n",
        "    \n",
        "  \n",
        "  return model, mesh, model_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KCPPEEi3T3Uv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updating keys from env and command line: ['run_name', 'model_name', 'async_checkpointing', 'checkpoint_period', 'base_output_directory', 'tokenizer_path', 'tokenizer_type', 'per_device_batch_size', 'steps', 'skip_jax_distributed_system', 'max_target_length']\n",
            "Running Model: llama3-8b\n",
            "Updating following parameters in config\n",
            "\n",
            "base_emb_dim: 4096\n",
            "base_num_query_heads: 32\n",
            "base_num_kv_heads: 8\n",
            "base_num_decoder_layers: 32\n",
            "base_mlp_dim: 14336\n",
            "head_dim: 128\n",
            "mlp_activations: ['silu', 'linear']\n",
            "vocab_size: 128256\n",
            "enable_dropout: False\n",
            "logits_via_embedding: False\n",
            "normalization_layer_epsilon: 1e-05\n",
            "rope_max_timescale: 500000\n",
            "decoder_block: llama2\n",
            "Updating keys from model: ['base_emb_dim', 'base_num_query_heads', 'base_num_kv_heads', 'base_num_decoder_layers', 'base_mlp_dim', 'head_dim', 'mlp_activations', 'vocab_size', 'enable_dropout', 'logits_via_embedding', 'normalization_layer_epsilon', 'rope_max_timescale', 'decoder_block']\n",
            "Skipping jax distributed system due to skip_jax_distributed_system=True flag.\n",
            "Not using emergency checkpoint, ignoring local_checkpoint_directory, local_checkpoint_period, use_replicator_service and replicator_backup_interval_minutes\n",
            "dataset_type set to tfds, will use keys['dataset_path']='' and keys['dataset_name']='c4/en:3.0.1'\n",
            "Config param activations_in_float32: False\n",
            "Config param adam_b1: 0.9\n",
            "Config param adam_b2: 0.95\n",
            "Config param adam_eps: 1e-08\n",
            "Config param adam_eps_root: 0.0\n",
            "Config param adam_weight_decay: 0.1\n",
            "Config param add_bos: True\n",
            "Config param add_eos: True\n",
            "Config param allow_split_physical_axes: False\n",
            "Config param ar_cache_axis_order: 1,2,0,3\n",
            "Config param async_checkpointing: False\n",
            "Config param attention: autoselected\n",
            "Config param attention_type: global\n",
            "Config param attn_logits_soft_cap: None\n",
            "Config param autoregressive_decode_assert: \n",
            "Config param base_emb_dim: 4096\n",
            "Config param base_mlp_dim: 14336\n",
            "Config param base_moe_mlp_dim: 7168\n",
            "Config param base_num_decoder_layers: 32\n",
            "Config param base_num_kv_heads: 8\n",
            "Config param base_num_query_heads: 32\n",
            "Config param base_output_directory: gs://dummy_output_dir\n",
            "Config param beta_fast: 32\n",
            "Config param beta_slow: 1\n",
            "Config param capacity_factor: -1.0\n",
            "Config param cast_logits_to_fp32: True\n",
            "Config param checkpoint_dir: gs://dummy_output_dir/test-tunix-maxtext-llama3-8b/checkpoints/\n",
            "Config param checkpoint_is_quantized: False\n",
            "Config param checkpoint_period: 5\n",
            "Config param checkpoint_storage_concurrent_gb: 96\n",
            "Config param checkpoint_storage_target_data_file_size_bytes: 2147483648\n",
            "Config param checkpoint_storage_use_ocdbt: True\n",
            "Config param checkpoint_storage_use_zarr3: True\n",
            "Config param chunk_attn_window_size: 0\n",
            "Config param collect_stack_trace: False\n",
            "Config param colocated_python_data_input: False\n",
            "Config param compile_topology: \n",
            "Config param compile_topology_num_slices: -1\n",
            "Config param compiled_trainstep_file: \n",
            "Config param compute_axis_order: 0,1,2,3\n",
            "Config param constant_bound_config: []\n",
            "Config param context: remat\n",
            "Config param context_parallel_load_balance: True\n",
            "Config param cosine_learning_rate_final_fraction: 0.1\n",
            "Config param custom_mesh: \n",
            "Config param data_sharding: (('data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'context', 'context_autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence', 'expert', 'autoregressive'),)\n",
            "Config param data_shuffle_seed: 0\n",
            "Config param dataset_name: c4/en:3.0.1\n",
            "Config param dataset_path: \n",
            "Config param dataset_type: tfds\n",
            "Config param dcn_autoregressive_parallelism: 1\n",
            "Config param dcn_context_autoregressive_parallelism: 1\n",
            "Config param dcn_context_parallelism: 1\n",
            "Config param dcn_data_parallelism: -1\n",
            "Config param dcn_expert_parallelism: 1\n",
            "Config param dcn_fsdp_parallelism: 1\n",
            "Config param dcn_fsdp_transpose_parallelism: 1\n",
            "Config param dcn_parallelism: [-1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Config param dcn_pipeline_parallelism: 1\n",
            "Config param dcn_sequence_parallelism: 1\n",
            "Config param dcn_tensor_parallelism: 1\n",
            "Config param dcn_tensor_sequence_parallelism: 1\n",
            "Config param dcn_tensor_transpose_parallelism: 1\n",
            "Config param decode_sampling_nucleus_p: -1\n",
            "Config param decode_sampling_strategy: greedy\n",
            "Config param decode_sampling_temperature: 1.0\n",
            "Config param decode_sampling_top_k: 0\n",
            "Config param decoder_block: DecoderBlockType.LLAMA2\n",
            "Config param decoder_layer_input: device\n",
            "Config param dpo_beta: 0.1\n",
            "Config param dpo_label_smoothing: 0.0\n",
            "Config param dropout_rate: 0.0\n",
            "Config param dtype: bfloat16\n",
            "Config param dtype_mm: float32\n",
            "Config param dump_hlo: False\n",
            "Config param dump_hlo_delete_local_after: True\n",
            "Config param dump_hlo_gcs_dir: \n",
            "Config param dump_hlo_local_dir: /tmp/xla_dump/\n",
            "Config param dump_hlo_module_name: jit_train_step\n",
            "Config param dump_hlo_upload_all: False\n",
            "Config param dump_hlo_xla_flags: \n",
            "Config param dump_step: -1\n",
            "Config param emb_dim: 4096\n",
            "Config param enable_checkpoint_cloud_logger: False\n",
            "Config param enable_checkpointing: True\n",
            "Config param enable_data_shuffling: True\n",
            "Config param enable_dropout: False\n",
            "Config param enable_emergency_checkpoint: False\n",
            "Config param enable_gcp_goodput_metrics: True\n",
            "Config param enable_gcp_step_deviation_metrics: True\n",
            "Config param enable_goodput_recording: False\n",
            "Config param enable_jax_profiler: False\n",
            "Config param enable_llm_inference_pool: False\n",
            "Config param enable_model_warmup: False\n",
            "Config param enable_padding_causal_mask: True\n",
            "Config param enable_pathways_goodput: False\n",
            "Config param enable_prefix_caching: False\n",
            "Config param enable_single_controller: False\n",
            "Config param enable_single_replica_ckpt_restoring: False\n",
            "Config param enable_tensorboard: True\n",
            "Config param eval_data_columns: ['text']\n",
            "Config param eval_dataset_name: c4/en:3.0.1\n",
            "Config param eval_image_column: image\n",
            "Config param eval_interval: -1\n",
            "Config param eval_per_device_batch_size: 1.0\n",
            "Config param eval_split: validation\n",
            "Config param eval_steps: -1\n",
            "Config param expansion_factor_real_data: -1\n",
            "Config param final_logits_soft_cap: None\n",
            "Config param first_num_dense_layers: 0\n",
            "Config param float32_logits: False\n",
            "Config param float32_qk_product: False\n",
            "Config param force_unroll: False\n",
            "Config param freeze_vision_encoder_params: True\n",
            "Config param fused_mlp: False\n",
            "Config param fused_qkv: False\n",
            "Config param gcs_metrics: False\n",
            "Config param generate_slice: v5e-16\n",
            "Config param global_batch_size_to_eval_on: 1\n",
            "Config param global_batch_size_to_load: 1\n",
            "Config param global_batch_size_to_load_eval: 1\n",
            "Config param global_batch_size_to_train_on: 1\n",
            "Config param global_parameter_scale: 1\n",
            "Config param goodput_upload_interval_seconds: 30\n",
            "Config param gradient_accumulation_steps: 1\n",
            "Config param gradient_clipping_threshold: 1.0\n",
            "Config param grain_eval_files: \n",
            "Config param grain_file_type: arrayrecord\n",
            "Config param grain_train_files: \n",
            "Config param grain_worker_count: 1\n",
            "Config param grain_worker_count_eval: 1\n",
            "Config param hardware: tpu\n",
            "Config param head_dim: 128\n",
            "Config param heartbeat_reporting_interval_in_seconds: 5\n",
            "Config param hf_data_dir: \n",
            "Config param hf_eval_files: \n",
            "Config param hf_eval_split: \n",
            "Config param hf_path: \n",
            "Config param hf_train_files: \n",
            "Config param hidden_size_for_vit: 1408\n",
            "Config param ici_autoregressive_parallelism: 1\n",
            "Config param ici_context_autoregressive_parallelism: 1\n",
            "Config param ici_context_parallelism: 1\n",
            "Config param ici_data_parallelism: 1\n",
            "Config param ici_expert_parallelism: 1\n",
            "Config param ici_fsdp_parallelism: -1\n",
            "Config param ici_fsdp_transpose_parallelism: 1\n",
            "Config param ici_parallelism: [1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Config param ici_pipeline_parallelism: 1\n",
            "Config param ici_sequence_parallelism: 1\n",
            "Config param ici_tensor_parallelism: 1\n",
            "Config param ici_tensor_sequence_parallelism: 1\n",
            "Config param ici_tensor_transpose_parallelism: 1\n",
            "Config param image_path: \n",
            "Config param image_placeholder: <|image|>\n",
            "Config param image_size_for_vit: 896\n",
            "Config param inference_benchmark_test: False\n",
            "Config param inference_metadata_file: \n",
            "Config param inference_microbenchmark_log_file_path: \n",
            "Config param inference_microbenchmark_loop_iters: 10\n",
            "Config param inference_microbenchmark_num_samples: [1, 2, 3, 4, 5]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config param inference_microbenchmark_prefill_lengths: 64,128,256,512,1024\n",
            "Config param inference_microbenchmark_stages: prefill,generate\n",
            "Config param inference_server: MaxtextInterleavedServer\n",
            "Config param inhomogeneous_layer_cycle_interval: 1\n",
            "Config param init_weights_seed: 0\n",
            "Config param input_data_sharding_logical_axes: ['activation_embed_and_logits_batch', 'activation_norm_length']\n",
            "Config param interleave_moe_layer_step: 1\n",
            "Config param intermediate_size_for_vit: 5632\n",
            "Config param jax_cache_dir: ~/jax_cache\n",
            "Config param jax_debug_log_modules: \n",
            "Config param jax_distributed_initialization_timeout: 300\n",
            "Config param jax_profiler_port: 9999\n",
            "Config param key_proj: remat\n",
            "Config param kv_lora_rank: 512\n",
            "Config param kv_quant_axis: heads_and_dkv\n",
            "Config param kv_quant_dtype: int8\n",
            "Config param learning_rate: 3e-05\n",
            "Config param learning_rate_schedule_steps: 10\n",
            "Config param load_balance_loss_weight: 0.01\n",
            "Config param load_from_prefill_dir: False\n",
            "Config param load_full_state_path: \n",
            "Config param load_parameters_path: \n",
            "Config param local_checkpoint_directory: \n",
            "Config param local_checkpoint_period: 0\n",
            "Config param local_rope_max_timescale: -1\n",
            "Config param log_config: True\n",
            "Config param log_period: 100\n",
            "Config param logical_axis_rules: (('activation_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_batch_no_exp', ('data', 'fsdp', 'fsdp_transpose')), ('activation_embed_and_logits_batch', ('data', 'stage', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_heads', ('tensor', 'tensor_transpose', 'sequence', 'tensor_sequence', 'autoregressive')), ('activation_kv_heads', ('tensor', 'tensor_transpose', 'sequence', 'tensor_sequence')), ('activation_length', ('sequence', 'context')), ('prefill_activation_length', ('sequence', 'context')), ('activation_length', ('context',)), ('activation_norm_length', ('tensor_sequence', 'context', 'sequence')), ('prefill_activation_norm_length', ('tensor_sequence', 'context', 'sequence')), ('activation_q_length', ('context',)), ('activation_kv_length', ()), ('activation_embed', ('tensor', 'tensor_transpose')), ('activation_mlp', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_kv', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_prefill_kv_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_kv_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_kv_head_dim', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_vocab', ('tensor', 'tensor_transpose', 'sequence', 'tensor_sequence')), ('activation_vocab', ('tensor', 'tensor_transpose')), ('activation_vocab', 'tensor_sequence'), ('activation_vocab', ('sequence', 'context')), ('activation_stage', 'stage'), ('activation_exp', ('expert',)), ('decode_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('decode_length', ('sequence',)), ('mlp', ('fsdp_transpose', 'tensor', 'tensor_sequence', 'autoregressive')), ('vocab', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('q_heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('kv_heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('embed', ('fsdp', 'fsdp_transpose', 'sequence', 'tensor_transpose', 'context', 'expert')), ('embed', ('fsdp', 'sequence', 'tensor_transpose', 'context', 'expert')), ('embed', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('embed', ('fsdp', 'sequence', 'context', 'expert')), ('embed_no_exp', ('fsdp', 'fsdp_transpose', 'sequence', 'tensor_transpose', 'context')), ('embed_no_exp', ('fsdp', 'sequence', 'tensor_transpose', 'context')), ('embed_no_exp', ('fsdp', 'fsdp_transpose', 'sequence', 'context')), ('embed_no_exp', ('fsdp', 'sequence', 'context')), ('embed_tensor_transpose', ('tensor_transpose',)), ('q_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'tensor_transpose', 'expert')), ('q_lora', ('fsdp', 'sequence', 'context', 'tensor_transpose', 'expert')), ('q_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('q_lora', ('fsdp', 'sequence', 'context', 'expert')), ('kv_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'tensor_transpose', 'expert')), ('kv_lora', ('fsdp', 'sequence', 'context', 'tensor_transpose', 'expert')), ('kv_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('kv_lora', ('fsdp', 'sequence', 'context', 'expert')), ('norm', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('layers', 'stage'), ('kv', ()), ('kv_head_dim', ()), ('cache_batch_prefill', ()), ('cache_batch', ()), ('cache_heads_none', ()), ('cache_heads', ('autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence')), ('cache_heads', ('autoregressive', 'tensor', 'tensor_sequence')), ('cache_kv', ()), ('cache_sequence', ()), ('exp', 'expert'), ('paged_kv_heads', ('tensor',)), ('num_pages', ()), ('tokens_per_page', ()), ('paged_kv_head_dim_size', ()))\n",
            "Config param logits_dot_in_fp32: False\n",
            "Config param logits_via_embedding: False\n",
            "Config param lora_input_adapters_path: \n",
            "Config param matmul_precision: default\n",
            "Config param max_checkify: False\n",
            "Config param max_corpus_chars: 10000000\n",
            "Config param max_position_embeddings: 163840\n",
            "Config param max_prefill_predict_length: 64\n",
            "Config param max_target_length: 8192\n",
            "Config param megablox: True\n",
            "Config param mesh_axes: ['data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'context', 'context_autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence', 'expert', 'autoregressive']\n",
            "Config param metrics_dir: gs://dummy_output_dir/test-tunix-maxtext-llama3-8b/metrics/\n",
            "Config param metrics_file: \n",
            "Config param micro_batch_size_to_eval_on: 1\n",
            "Config param micro_batch_size_to_train_on: 1\n",
            "Config param mla_naive_kvcache: True\n",
            "Config param mlp_activations: ['silu', 'linear']\n",
            "Config param mlp_dim: 14336\n",
            "Config param mlpwi: remat\n",
            "Config param mlpwi_0: remat\n",
            "Config param mlpwi_1: remat\n",
            "Config param mlpwo: remat\n",
            "Config param model_call_mode: \n",
            "Config param model_fsdp_ag_once: False\n",
            "Config param model_name: llama3-8b\n",
            "Config param moe_mlp_dim: 7168\n",
            "Config param monitor_goodput: False\n",
            "Config param monitor_step_time_deviation: True\n",
            "Config param mscale: 1.0\n",
            "Config param mtp_eval_target_module: 0\n",
            "Config param mtp_loss_scaling_factor: 0.1\n",
            "Config param mtp_num_layers: 0\n",
            "Config param mu_dtype: float32\n",
            "Config param multi_sampling: False\n",
            "Config param n_routing_groups: -1\n",
            "Config param nope_layer_interval: -1\n",
            "Config param normalization_layer_epsilon: 1e-05\n",
            "Config param normalize_embedding_logits: True\n",
            "Config param num_attention_heads_for_vit: 16\n",
            "Config param num_channels_for_vit: 3\n",
            "Config param num_decoder_layers: 32\n",
            "Config param num_epoch: 1\n",
            "Config param num_experts: 1\n",
            "Config param num_experts_per_tok: 1\n",
            "Config param num_hidden_layers_for_vit: 34\n",
            "Config param num_kv_heads: 8\n",
            "Config param num_layers_per_pipeline_stage: 1\n",
            "Config param num_pipeline_microbatches: -1\n",
            "Config param num_pipeline_repeats: -1\n",
            "Config param num_query_heads: 32\n",
            "Config param num_slices: 1\n",
            "Config param opt_type: adamw\n",
            "Config param optimize_mesh_for_tpu_v6e: False\n",
            "Config param optimizer_memory_host_offload: False\n",
            "Config param original_max_position_embeddings: 4096\n",
            "Config param out_proj: remat\n",
            "Config param override_model_config: False\n",
            "Config param packing: True\n",
            "Config param pagedattn_head_dim_alignment: 128\n",
            "Config param pagedattn_max_pages_per_group: 256\n",
            "Config param pagedattn_num_pages: 64\n",
            "Config param pagedattn_pages_per_compute_block: 4\n",
            "Config param pagedattn_tokens_per_page: 32\n",
            "Config param param_scan_axis: 1\n",
            "Config param parameter_memory_host_offload: False\n",
            "Config param patch_size_for_vit: 14\n",
            "Config param per_device_batch_size: 1.0\n",
            "Config param pipeline_delay_activation_forwarding: False\n",
            "Config param pipeline_fsdp_ag_once: False\n",
            "Config param pipeline_parallel_layers: -1\n",
            "Config param pixel_shuffle_ratio_for_vit: 0.5\n",
            "Config param prefill_cache_axis_order: 1,2,0,3\n",
            "Config param prefill_cache_dir: \n",
            "Config param prefill_chunk_size: 256\n",
            "Config param prefill_slice: v5e-16\n",
            "Config param prefix_caching_dram_byte: 100000000000\n",
            "Config param prefix_caching_hbm_byte: 10000000000\n",
            "Config param profile_cleanly: True\n",
            "Config param profile_periodically_period: -1\n",
            "Config param profiler: \n",
            "Config param profiler_steps: 5\n",
            "Config param projector_dropout_for_vit: 0.0\n",
            "Config param projector_input_dim_for_vit: 4096\n",
            "Config param projector_output_dim_for_vit: 4096\n",
            "Config param prometheus_port: 0\n",
            "Config param prompt: I love to\n",
            "Config param q_lora_rank: 0\n",
            "Config param qk_nope_head_dim: 128\n",
            "Config param qk_rope_head_dim: 64\n",
            "Config param qkv_proj: remat\n",
            "Config param quant_cfg_path: \n",
            "Config param quantization: \n",
            "Config param quantization_local_shard_count: 1\n",
            "Config param quantize_kvcache: False\n",
            "Config param query_proj: remat\n",
            "Config param ragged_block_size: 256\n",
            "Config param record_internal_nn_metrics: 0\n",
            "Config param remat_policy: full\n",
            "Config param remat_policy_for_vit: minimal\n",
            "Config param replicate_quant_scale: False\n",
            "Config param replicator_backup_interval_minutes: 0\n",
            "Config param report_heartbeat_metric_for_gcp_monitoring: False\n",
            "Config param report_performance_metric_for_gcp_monitoring: False\n",
            "Config param reshape_q: False\n",
            "Config param return_log_prob: False\n",
            "Config param reuse_example_batch: 0\n",
            "Config param rope_factor: 40\n",
            "Config param rope_max_timescale: 500000\n",
            "Config param rope_min_timescale: 1\n",
            "Config param rope_theta_for_vit: 10000\n",
            "Config param rope_type: default\n",
            "Config param rope_use_scale: True\n",
            "Config param routed_bias: False\n",
            "Config param routed_scaling_factor: 1.0\n",
            "Config param routed_score_func: \n",
            "Config param run_name: test-tunix-maxtext-llama3-8b\n",
            "Config param sa_block_kv: 512\n",
            "Config param sa_block_kv_compute: 512\n",
            "Config param sa_block_kv_dkv: 512\n",
            "Config param sa_block_kv_dkv_compute: 512\n",
            "Config param sa_block_kv_dq: 512\n",
            "Config param sa_block_q: 512\n",
            "Config param sa_block_q_dkv: 512\n",
            "Config param sa_block_q_dq: 512\n",
            "Config param sa_k_layout: HEAD_DIM_MINOR\n",
            "Config param sa_q_layout: HEAD_DIM_MINOR\n",
            "Config param sa_use_fused_bwd_kernel: False\n",
            "Config param sa_v_layout: HEAD_DIM_MINOR\n",
            "Config param save_config_to_gcs: False\n",
            "Config param save_quantized_params_path: \n",
            "Config param scan_layers: True\n",
            "Config param scan_layers_per_stage: False\n",
            "Config param scan_pipeline_iterations: True\n",
            "Config param set_remat_policy_on_layers_per_stage: False\n",
            "Config param set_remat_policy_on_pipeline_iterations: True\n",
            "Config param sft_train_on_completion_only: False\n",
            "Config param sharding_tolerance: 0.02\n",
            "Config param shardy: True\n",
            "Config param shared_experts: 1\n",
            "Config param skip_first_n_steps_for_profiler: 1\n",
            "Config param skip_jax_distributed_system: True\n",
            "Config param sliding_window_size: 0\n",
            "Config param sparse_matmul: True\n",
            "Config param stack_prefill_result_cache: False\n",
            "Config param stack_trace_interval_seconds: 600\n",
            "Config param stack_trace_to_cloud: False\n",
            "Config param step_deviation_interval_seconds: 30\n",
            "Config param steps: 10\n",
            "Config param subslice_shape: \n",
            "Config param target_eval_loss: 0.0\n",
            "Config param temperature_tuning: False\n",
            "Config param tensorboard_dir: gs://dummy_output_dir/test-tunix-maxtext-llama3-8b/tensorboard/\n",
            "Config param tile_activation_dim: 1024\n",
            "Config param tile_batch_seq: 512\n",
            "Config param tile_size_for_vit: 336\n",
            "Config param tile_weight_dim: 1024\n",
            "Config param tokenize_eval_data: True\n",
            "Config param tokenize_train_data: True\n",
            "Config param tokenizer_path: ../../maxtext/assets/tokenizer_llama3.tiktoken\n",
            "Config param tokenizer_type: tiktoken\n",
            "Config param topk_routing_group: -1\n",
            "Config param train_data_columns: ['text']\n",
            "Config param train_image_column: image\n",
            "Config param train_split: train\n",
            "Config param trainable_position_size: -1\n",
            "Config param upload_all_profiler_results: False\n",
            "Config param use_chat_template: False\n",
            "Config param use_chunked_prefill: False\n",
            "Config param use_dpo: False\n",
            "Config param use_iota_embed: False\n",
            "Config param use_multimodal: False\n",
            "Config param use_post_attn_norm: False\n",
            "Config param use_post_ffw_norm: False\n",
            "Config param use_qk_norm: False\n",
            "Config param use_ragged_attention: False\n",
            "Config param use_random_routing: False\n",
            "Config param use_replicator_service: False\n",
            "Config param use_sft: False\n",
            "Config param use_untrainable_positional_embedding: False\n",
            "Config param use_vertex_tensorboard: False\n",
            "Config param using_pipeline_parallelism: False\n",
            "Config param v_head_dim: 128\n",
            "Config param value_proj: remat\n",
            "Config param vertex_tensorboard_project: \n",
            "Config param vertex_tensorboard_region: \n",
            "Config param vision_output_dim_for_vit: 4096\n",
            "Config param vocab_size: 128256\n",
            "Config param warmup_steps_fraction: 0.1\n",
            "Config param weight_dtype: float32\n",
            "Num_devices: 1, shape (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "\"No RngStream named 'dropout' found in Rngs.\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Base model\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# gemma, mesh, model_config = get_base_model(\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#     ckpt_path=os.path.join(INTERMEDIATE_CKPT_DIR, \"state\")\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m gemma, mesh, model_config = \u001b[43mget_ref_maxtext_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# gemma_maxtext_nnx = nnx.bridge.ToNNX(gemma)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Instead of:\u001b[39;00m\n\u001b[32m      9\u001b[39m nnx.display(gemma)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mget_ref_maxtext_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     32\u001b[39m dummy_pos    = jnp.zeros_like(dummy_tokens)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Anisha: using ToNNX bridge\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m model = \u001b[43mnnx_wrappers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mToNNX\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrngs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRngs\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m                                                              \u001b[49m\u001b[43mdecoder_positions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdummy_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m                                                              \u001b[49m\u001b[43mdecoder_segment_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m#TODO: @mazumdera: change this to extract decoder_segment_ids from attention mask\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m \u001b[38;5;66;03m#       use_attention_mask=False,  # trust Tunix loss masking\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m#   )\u001b[39;00m\n\u001b[32m     49\u001b[39m mesh  = model.mesh\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/maxtext/MaxText/layers/nnx_wrappers.py:215\u001b[39m, in \u001b[36mToNNX.lazy_init\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_init\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    214\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"A shortcut of calling `nnx.bridge.lazy_init()` upon this module.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/maxtext/MaxText/layers/nnx_wrappers.py:163\u001b[39m, in \u001b[36mlazy_init\u001b[39m\u001b[34m(fn, *args, **kwargs)\u001b[39m\n\u001b[32m    161\u001b[39m _set_initializing(module, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m   _ = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    165\u001b[39m   _set_initializing(module, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/maxtext/MaxText/layers/nnx_wrappers.py:247\u001b[39m, in \u001b[36mToNNX.__call__\u001b[39m\u001b[34m(self, rngs, method, *args, **kwargs)\u001b[39m\n\u001b[32m    245\u001b[39m   _rngs[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m] = _rngs.pop(\u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._object__state.initializing:\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m   out, updates = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_nnx__module\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit_with_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_rngs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    251\u001b[39m   nnx_attrs = {\n\u001b[32m    252\u001b[39m     k: v\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(\u001b[38;5;28mself\u001b[39m).items()\n\u001b[32m    254\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m k.startswith(\u001b[33m\"\u001b[39m\u001b[33mto_nnx__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m k.startswith(\u001b[33m\"\u001b[39m\u001b[33m_object__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    255\u001b[39m   }\n",
            "    \u001b[31m[... skipping hidden 7 frame]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/maxtext/MaxText/layers/models.py:117\u001b[39m, in \u001b[36mTransformer.__call__\u001b[39m\u001b[34m(self, decoder_input_tokens, decoder_positions, decoder_segment_ids, encoder_images, enable_dropout, model_mode, previous_chunk, true_length, slot, page_state, decoder_target_tokens, decoder_target_mask)\u001b[39m\n\u001b[32m    114\u001b[39m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.decoder_block == DecoderBlockType.LLAMA4:\n\u001b[32m    115\u001b[39m     bidirectional_mask = decoder_input_tokens == multimodal_utils.LLAMA4_PATCH_TOKEN\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m logits, hidden_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_positions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_segment_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_segment_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43menable_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprevious_chunk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprevious_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mslot\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpage_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbidirectional_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbidirectional_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# If we are initializing the model AND MTP is enabled, we must create\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# dummy target tensors. This allows Flax to trace the MTPBlock and create\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# all its necessary parameters, without requiring the main training pipeline\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# to be aware of this initialization detail.\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_initializing() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.mtp_num_layers > \u001b[32m0\u001b[39m:\n",
            "    \u001b[31m[... skipping hidden 2 frame]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/maxtext/MaxText/layers/decoders.py:700\u001b[39m, in \u001b[36mDecoder.__call__\u001b[39m\u001b[34m(self, decoder_input_tokens, decoder_positions, decoder_segment_ids, deterministic, model_mode, previous_chunk, slot, page_state, bidirectional_mask, image_embeddings)\u001b[39m\n\u001b[32m    695\u001b[39m       layer_kwargs = {\n\u001b[32m    696\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnope_layer_interval\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.config.nope_layer_interval,\n\u001b[32m    697\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33minterleave_moe_layer_step\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.config.interleave_moe_layer_step,\n\u001b[32m    698\u001b[39m       }\n\u001b[32m    699\u001b[39m       broadcast_args += (bidirectional_mask,)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     y, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_decoder_layers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mRemattedBlockLayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscan_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlayers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_axes_tuple\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbroadcast_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlayer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mbroadcast_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    710\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m cfg.decoder_block == DecoderBlockType.DEEPSEEK:\n",
            "    \u001b[31m[... skipping hidden 3 frame]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/venv-py311/lib/python3.11/site-packages/flax/core/axes_scan.py:185\u001b[39m, in \u001b[36mscan.<locals>.scan_fn\u001b[39m\u001b[34m(broadcast_in, init, *args)\u001b[39m\n\u001b[32m    181\u001b[39m f_flat, out_tree = jax.api_util.flatten_fun_nokwargs(\n\u001b[32m    182\u001b[39m     lu.wrap_init(broadcast_body, debug_info=debug_info), in_tree\n\u001b[32m    183\u001b[39m )\n\u001b[32m    184\u001b[39m in_pvals = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(pe.PartialVal.unknown, in_avals))\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m _, out_pvals, _ = \u001b[43mpe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m out_flat = []\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pv, const \u001b[38;5;129;01min\u001b[39;00m out_pvals:\n",
            "    \u001b[31m[... skipping hidden 7 frame]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/venv-py311/lib/python3.11/site-packages/flax/core/axes_scan.py:156\u001b[39m, in \u001b[36mscan.<locals>.scan_fn.<locals>.body_fn\u001b[39m\u001b[34m(c, xs, init_mode)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbody_fn\u001b[39m(c, xs, init_mode=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    152\u001b[39m   \u001b[38;5;66;03m# inject constants\u001b[39;00m\n\u001b[32m    153\u001b[39m   xs = jax.tree_util.tree_map(\n\u001b[32m    154\u001b[39m       \u001b[38;5;28;01mlambda\u001b[39;00m ax, arg, x: (arg \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m broadcast \u001b[38;5;28;01melse\u001b[39;00m x), in_axes, args, xs\n\u001b[32m    155\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m   broadcast_out, c, ys = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbroadcast_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m init_mode:\n\u001b[32m    159\u001b[39m     ys = jax.tree_util.tree_map(\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m ax, y: (y \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m broadcast \u001b[38;5;28;01melse\u001b[39;00m ()), out_axes, ys\n\u001b[32m    161\u001b[39m     )\n",
            "    \u001b[31m[... skipping hidden 18 frame]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/maxtext/MaxText/layers/llama2.py:139\u001b[39m, in \u001b[36mLlamaDecoderLayer.__call__\u001b[39m\u001b[34m(self, inputs, decoder_segment_ids, decoder_positions, deterministic, model_mode, slot, page_state, previous_chunk)\u001b[39m\n\u001b[32m    136\u001b[39m hidden_states = nn.with_logical_constraint(hidden_states, activation_axis_names)\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# MLP block.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m mlp_lnx = \u001b[43mmlp_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintermediate_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmlp_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmlp_activations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintermediate_dropout_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmlp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m mlp_lnx = nn.with_logical_constraint(mlp_lnx, activation_axis_names)\n\u001b[32m    153\u001b[39m layer_output = mlp_lnx + intermediate_inputs\n",
            "    \u001b[31m[... skipping hidden 2 frame]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/maxtext/MaxText/layers/nnx_wrappers.py:391\u001b[39m, in \u001b[36mToLinen.__call__\u001b[39m\u001b[34m(self, nnx_method, *args, **kwargs)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;66;03m# init codepath\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_initializing():\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m   module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnnx_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_module_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m   \u001b[38;5;66;03m# TODO: add lazy_init here in case there's an `ToNNX` submodule under `module`.\u001b[39;00m\n\u001b[32m    393\u001b[39m   \u001b[38;5;66;03m# update linen variables before call module to save initial state\u001b[39;00m\n\u001b[32m    394\u001b[39m   \u001b[38;5;28mself\u001b[39m._update_variables(module)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/venv-py311/lib/python3.11/site-packages/flax/nnx/object.py:289\u001b[39m, in \u001b[36mObjectMeta.__call__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_graph_node_meta_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/venv-py311/lib/python3.11/site-packages/flax/nnx/object.py:300\u001b[39m, in \u001b[36m_graph_node_meta_call\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    298\u001b[39m vars_obj[\u001b[33m'\u001b[39m\u001b[33m_object__state\u001b[39m\u001b[33m'\u001b[39m] = ObjectState()\n\u001b[32m    299\u001b[39m vars_obj[\u001b[33m'\u001b[39m\u001b[33m_object__nodes\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mcls\u001b[39m._object__nodes\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object_meta_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;66;03m# register possible new data attributes after initialization\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m vars_obj.items():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/venv-py311/lib/python3.11/site-packages/flax/nnx/object.py:292\u001b[39m, in \u001b[36mObjectMeta._object_meta_construct\u001b[39m\u001b[34m(cls, self, *args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_object_meta_construct\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/maxtext/MaxText/layers/linears.py:386\u001b[39m, in \u001b[36mMlpBlock.__init__\u001b[39m\u001b[34m(self, config, in_features, intermediate_dim, activations, kernel_init, intermediate_dropout_rate, dtype, weight_dtype, use_bias, use_pre_norm, quant, model_mode, rngs)\u001b[39m\n\u001b[32m    373\u001b[39m     module = DenseGeneral(\n\u001b[32m    374\u001b[39m         in_features_shape=in_features,\n\u001b[32m    375\u001b[39m         out_features_shape=\u001b[38;5;28mself\u001b[39m.intermediate_dim,\n\u001b[32m   (...)\u001b[39m\u001b[32m    383\u001b[39m         rngs=rngs,\n\u001b[32m    384\u001b[39m     )\n\u001b[32m    385\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, dense_name, module)\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28mself\u001b[39m.dropout = \u001b[43mnnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate_dropout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbroadcast_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrngs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrngs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;28mself\u001b[39m.wo = DenseGeneral(\n\u001b[32m    388\u001b[39m     in_features_shape=\u001b[38;5;28mself\u001b[39m.intermediate_dim,\n\u001b[32m    389\u001b[39m     out_features_shape=in_features,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     rngs=rngs,\n\u001b[32m    398\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/venv-py311/lib/python3.11/site-packages/flax/nnx/object.py:289\u001b[39m, in \u001b[36mObjectMeta.__call__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_graph_node_meta_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/venv-py311/lib/python3.11/site-packages/flax/nnx/object.py:300\u001b[39m, in \u001b[36m_graph_node_meta_call\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    298\u001b[39m vars_obj[\u001b[33m'\u001b[39m\u001b[33m_object__state\u001b[39m\u001b[33m'\u001b[39m] = ObjectState()\n\u001b[32m    299\u001b[39m vars_obj[\u001b[33m'\u001b[39m\u001b[33m_object__nodes\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mcls\u001b[39m._object__nodes\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object_meta_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;66;03m# register possible new data attributes after initialization\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m vars_obj.items():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/venv-py311/lib/python3.11/site-packages/flax/nnx/object.py:292\u001b[39m, in \u001b[36mObjectMeta._object_meta_construct\u001b[39m\u001b[34m(cls, self, *args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_object_meta_construct\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/venv-py311/lib/python3.11/site-packages/flax/nnx/nn/stochastic.py:85\u001b[39m, in \u001b[36mDropout.__init__\u001b[39m\u001b[34m(self, rate, broadcast_dims, deterministic, rng_collection, rngs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28mself\u001b[39m.rng_collection = rng_collection\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rngs, rnglib.Rngs):\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m   \u001b[38;5;28mself\u001b[39m.rngs = \u001b[43mrngs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrng_collection\u001b[49m\u001b[43m]\u001b[49m.fork()\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rngs, rnglib.RngStream):\n\u001b[32m     87\u001b[39m   \u001b[38;5;28mself\u001b[39m.rngs = rngs.fork()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/venv-py311/lib/python3.11/site-packages/flax/nnx/rnglib.py:179\u001b[39m, in \u001b[36mRngs.__getitem__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;167;43;01mKeyError\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/venv-py311/lib/python3.11/site-packages/flax/nnx/rnglib.py:171\u001b[39m, in \u001b[36mRngs._get_stream\u001b[39m\u001b[34m(self, name, error_type)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stream_vars:\n\u001b[32m    170\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stream_vars:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_type(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo RngStream named \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m found in Rngs.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    172\u001b[39m   stream = stream_vars[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mKeyError\u001b[39m: \"No RngStream named 'dropout' found in Rngs.\""
          ]
        }
      ],
      "source": [
        "# Base model\n",
        "# gemma, mesh, model_config = get_base_model(\n",
        "#     ckpt_path=os.path.join(INTERMEDIATE_CKPT_DIR, \"state\")\n",
        "# )\n",
        "\n",
        "gemma, mesh, model_config = get_ref_maxtext_model()\n",
        "# gemma_maxtext_nnx = nnx.bridge.ToNNX(gemma)\n",
        "# Instead of:\n",
        "nnx.display(gemma)\n",
        "\n",
        "# Use:\n",
        "print(\"Model initialized successfully\")\n",
        "print(f\"Model mesh shape: {mesh.shape}\")\n",
        "print(f\"Model config: {model_config}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFKUZT10T3Uv"
      },
      "outputs": [],
      "source": [
        "# def get_base_model(ckpt_path):\n",
        "\n",
        "#   model_config = gemma_lib.TransformerConfig.gemma_2b()\n",
        "#   mesh = jax.make_mesh(*MESH)\n",
        "#   abs_gemma: nnx.Module = nnx.eval_shape(\n",
        "#       lambda: gemma_lib.Transformer(model_config, rngs=nnx.Rngs(params=0))\n",
        "#   )\n",
        "#   abs_state = nnx.state(abs_gemma)\n",
        "#   abs_state = jax.tree.map(\n",
        "#       lambda a, s: jax.ShapeDtypeStruct(a.shape, jnp.bfloat16, sharding=s),\n",
        "#       abs_state,\n",
        "#       nnx.get_named_sharding(abs_state, mesh),\n",
        "#   )\n",
        "#   checkpointer = ocp.StandardCheckpointer()\n",
        "#   restored_params = checkpointer.restore(ckpt_path, target=abs_state)\n",
        "\n",
        "#   graph_def, _ = nnx.split(abs_gemma)\n",
        "#   gemma = nnx.merge(graph_def, restored_params)\n",
        "#   return gemma, mesh, model_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2iDYbnsT3Uv"
      },
      "source": [
        "## Prompt the model\n",
        "\n",
        "Let's see how the model performs on the English-French translation task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iH82cHpAT3Uv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------\n",
            "Prompt:\n",
            "Translate this into French:\n",
            "Hello, my name is Morgane.\n",
            "\n",
            "Output:\n",
            " life HEn se<unused82>                    L it</blockquote>\n",
            "----------------------\n",
            "Prompt:\n",
            "Translate this into French:\n",
            "This dish is delicious!\n",
            "\n",
            "Output:\n",
            " life HEn se<unused82>                    L it</blockquote>\n",
            "----------------------\n",
            "Prompt:\n",
            "Translate this into French:\n",
            "I am a student.\n",
            "\n",
            "Output:\n",
            " life HEn se<unused82>                    L it</blockquote>\n",
            "----------------------\n",
            "Prompt:\n",
            "Translate this into French:\n",
            "How's the weather today?\n",
            "\n",
            "Output:\n",
            " life HEn se<unused82>                    L it</blockquote>\n"
          ]
        }
      ],
      "source": [
        "gemma_tokenizer = data_lib.GemmaTokenizer(\n",
        "    os.path.join(kaggle_ckpt_path, \"tokenizer.model\")\n",
        ")\n",
        "\n",
        "from MaxText.input_pipeline import _input_pipeline_utils\n",
        "from MaxText.globals import PKG_DIR\n",
        "\n",
        "# gemma_tokenizer = _input_pipeline_utils.get_tokenizer(\n",
        "#         os.path.join(os.path.dirname(PKG_DIR), \"assets\", \"tokenizer_llama3.tiktoken\"),\n",
        "#         \"tiktoken\",\n",
        "#         add_bos=True,\n",
        "#         add_eos=False,\n",
        "#     )\n",
        "#     )\n",
        "# gemma_tokenizer = data_lib.GemmaTokenizer(\n",
        "# )\n",
        "\n",
        "sampler = sampler_lib.Sampler(\n",
        "    transformer=gemma,\n",
        "    tokenizer=gemma_tokenizer,\n",
        "    cache_config=sampler_lib.CacheConfig(\n",
        "        cache_size=256,\n",
        "        num_layers=model_config.num_layers,\n",
        "        num_kv_heads=model_config.num_kv_heads,\n",
        "        head_dim=model_config.head_dim,\n",
        "    ),\n",
        ")\n",
        "\n",
        "input_batch = [\n",
        "    \"Translate this into French:\\nHello, my name is Morgane.\\n\",\n",
        "    \"Translate this into French:\\nThis dish is delicious!\\n\",\n",
        "    \"Translate this into French:\\nI am a student.\\n\",\n",
        "    \"Translate this into French:\\nHow's the weather today?\\n\",\n",
        "]\n",
        "\n",
        "out_data = sampler(\n",
        "    input_strings=input_batch,\n",
        "    total_generation_steps=10,  # The number of steps performed when generating a response.\n",
        ")\n",
        "\n",
        "for input_string, out_string in zip(input_batch, out_data.text):\n",
        "  print(f\"----------------------\")\n",
        "  print(f\"Prompt:\\n{input_string}\")\n",
        "  print(f\"Output:\\n{out_string}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdxn7DQYT3Uv"
      },
      "source": [
        "## Apply LoRA/QLoRA to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3t-7leAT3Uv"
      },
      "outputs": [],
      "source": [
        "def get_lora_model(base_model, mesh):\n",
        "  lora_provider = lora.LoraProvider(\n",
        "      module_path=\".*q_einsum|.*kv_einsum|.*gate_proj|.*down_proj|.*up_proj\",\n",
        "      rank=RANK,\n",
        "      alpha=ALPHA,\n",
        "      # comment the two args below for LoRA (w/o quantisation).\n",
        "      weight_qtype=\"nf4\",\n",
        "      tile_size=256,\n",
        "  )\n",
        "\n",
        "  model_input = base_model.get_model_input()\n",
        "  lora_model = lora.apply_lora_to_model(\n",
        "      base_model, lora_provider, **model_input\n",
        "  )\n",
        "\n",
        "  with mesh:\n",
        "    state = nnx.state(lora_model)\n",
        "    pspecs = nnx.get_partition_spec(state)\n",
        "    sharded_state = jax.lax.with_sharding_constraint(state, pspecs)\n",
        "    nnx.update(lora_model, sharded_state)\n",
        "\n",
        "  return lora_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfmodoqrT3Uv"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'get_lora_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# LoRA model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m lora_gemma = \u001b[43mget_lora_model\u001b[49m(gemma, mesh=mesh)\n\u001b[32m      3\u001b[39m nnx.display(lora_gemma)\n",
            "\u001b[31mNameError\u001b[39m: name 'get_lora_model' is not defined"
          ]
        }
      ],
      "source": [
        "# LoRA model\n",
        "lora_gemma = get_lora_model(gemma, mesh=mesh)\n",
        "nnx.display(lora_gemma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD6-iU0PT3Uv"
      },
      "source": [
        "## Load Datasets for SFT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T_7Cik8T3Uv"
      },
      "outputs": [],
      "source": [
        "# Loads the training and validation datasets\n",
        "train_ds, validation_ds = data_lib.create_datasets(\n",
        "    dataset_name='mtnt/en-fr',\n",
        "    # Uncomment the line below to use a Hugging Face dataset.\n",
        "    # Note that this requires upgrading the 'datasets' package and restarting\n",
        "    # the Colab runtime.\n",
        "    # dataset_name='Helsinki-NLP/opus-100',\n",
        "    global_batch_size=BATCH_SIZE,\n",
        "    max_target_length=256,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    tokenizer=gemma_tokenizer,\n",
        ")\n",
        "\n",
        "\n",
        "def gen_model_input_fn(x: peft_trainer.TrainingInput):\n",
        "  pad_mask = x.input_tokens != gemma_tokenizer.pad_id()\n",
        "  positions = gemma_lib.build_positions_from_mask(pad_mask)\n",
        "  attention_mask = gemma_lib.make_causal_attn_mask(pad_mask)\n",
        "  return {\n",
        "      'input_tokens': x.input_tokens,\n",
        "      'input_mask': x.input_mask,\n",
        "      'positions': positions,\n",
        "      'attention_mask': attention_mask,\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w0PHlVBT3Uv"
      },
      "source": [
        "## SFT Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh1xPieRT3Uv"
      },
      "source": [
        "### Training with full weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oYR9JKNT3Uv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87ad1b1fd16b431991135f9a7f8cb42f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/100 [00:00<?, ?step/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "logging_option = metrics_logger.MetricsLoggerOptions(\n",
        "    log_dir=\"/tmp/tensorboard/full\", flush_every_n_steps=20\n",
        ")\n",
        "training_config = peft_trainer.TrainingConfig(\n",
        "    eval_every_n_steps=EVAL_EVERY_N_STEPS,\n",
        "    max_steps=MAX_STEPS,\n",
        "    metrics_logging_options=logging_option,\n",
        ")\n",
        "trainer = peft_trainer.PeftTrainer(gemma, optax.adamw(1e-5), training_config)\n",
        "trainer = trainer.with_gen_model_input_fn(gen_model_input_fn)\n",
        "\n",
        "with jax.profiler.trace(os.path.join(PROFILING_DIR, \"full_training\")):\n",
        "  with mesh:\n",
        "    trainer.train(train_ds, validation_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gd-66SRT3Uv"
      },
      "source": [
        "### Training with LoRA/QLoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZVp0SYMT3Uv"
      },
      "outputs": [],
      "source": [
        "# Restart Colab runtime.\n",
        "\n",
        "training_config = peft_trainer.TrainingConfig(\n",
        "    eval_every_n_steps=EVAL_EVERY_N_STEPS,\n",
        "    max_steps=MAX_STEPS,\n",
        "    checkpoint_root_directory=CKPT_DIR,\n",
        ")\n",
        "lora_trainer = peft_trainer.PeftTrainer(\n",
        "    lora_gemma, optax.adamw(1e-3), training_config\n",
        ").with_gen_model_input_fn(gen_model_input_fn)\n",
        "\n",
        "with jax.profiler.trace(os.path.join(PROFILING_DIR, \"peft\")):\n",
        "  with mesh:\n",
        "    lora_trainer.train(train_ds, validation_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXUzmyVIT3Uv"
      },
      "source": [
        "### Compare profile results of different training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIw2rIKmT3Uv"
      },
      "source": [
        "<font size=3>Setup<font>           | <font size=3>Train Step Time<font> | <font size=3>Peak Memory Usage<font>\n",
        "---------------------------------- | ---------------------------------- | ------------------------------\n",
        "<font size=3>Full weights<font>        |   <font size=3>~1.22 s<font>     |   <font size=3>43.26 GiB<font>\n",
        "<font size=3>QLoRA<font>        |   <font size=3>~1.19 s<font>     |   <font size=3>28.14 GiB<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QICLDHTkT3Uv"
      },
      "source": [
        "## Generate with the LoRA/QLoRA model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTsmUCK6T3Uv"
      },
      "source": [
        "The QLoRA model still cannot do English-to-French translation properly since we\n",
        "only trained for 100 steps. If you train it for longer, you will see better\n",
        "results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WohZCuY0T3Uw"
      },
      "outputs": [],
      "source": [
        "gemma_tokenizer = data_lib.GemmaTokenizer(\n",
        "    os.path.join(kaggle_ckpt_path, \"tokenizer.model\")\n",
        ")\n",
        "\n",
        "sampler = sampler_lib.Sampler(\n",
        "    transformer=lora_gemma,\n",
        "    tokenizer=gemma_tokenizer,\n",
        "    cache_config=sampler_lib.CacheConfig(\n",
        "        cache_size=256,\n",
        "        num_layers=model_config.num_layers,\n",
        "        num_kv_heads=model_config.num_kv_heads,\n",
        "        head_dim=model_config.head_dim,\n",
        "    ),\n",
        ")\n",
        "\n",
        "input_batch = [\n",
        "    \"Translate this into French:\\nHello, my name is Morgane.\\n\",\n",
        "    \"Translate this into French:\\nThis dish is delicious!\\n\",\n",
        "    \"Translate this into French:\\nI am a student.\\n\",\n",
        "    \"Translate this into French:\\nHow's the weather today?\\n\",\n",
        "]\n",
        "\n",
        "out_data = sampler(\n",
        "    input_strings=input_batch,\n",
        "    total_generation_steps=10,  # The number of steps performed when generating a response.\n",
        ")\n",
        "\n",
        "for input_string, out_string in zip(input_batch, out_data.text):\n",
        "  print(f\"----------------------\")\n",
        "  print(f\"Prompt:\\n{input_string}\")\n",
        "  print(f\"Output:\\n{out_string}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//third_party/py/tunix/google/examples/qlora_gemma:qlora_demo_colab",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/py/tunix/google/examples/qlora_gemma/qlora_demo.ipynb",
          "timestamp": 1745566103252
        }
      ]
    },
    "kernelspec": {
      "display_name": "venv-py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
